
ARG BASE_IMAGE
ARG BASE_IMAGE_TAG

FROM ${BASE_IMAGE:?err}:${BASE_IMAGE_TAG:?err} AS base-image

# ===Remove Jetson-container unused install========================================================
RUN rm --recursive --force /ros_deep_learning \
  && rm --recursive --force /jetson-inference

FROM scratch AS squash-base-image
#FROM nvcr.io/nvidia/l4t-jetpack:${TAG_OS_VERSION:?err} AS squash-base-image
#FROM nvcr.io/nvidia/l4t-base:${TAG_OS_VERSION:?err} AS squash-base-image # ToDo: validate using l4t-base instead of l4t-jetson
#FROM docker.io/arm64v8/ubuntu:20.04 AS squash-base-image
COPY --from=base-image / /
# Note:
#   - The squash-base-image stage is a workaround to prevent the "max depth exceeded" error
#        occuring when the maximum number of docker layer as been reached.
#   - We use arm64v8/ubuntu:20.04 as base image since we are copying everything from l4t-jetpack anyway
#   - About nvidia l4t  base images:
#       - nvcr.io/nvidia/l4t-base install the core CUDA ressources
#       - nvcr.io/nvidia/l4t-jetpack
#           - install several dev package such as nvidia-cuda-dev, nvidia-cudnn-dev and nvidia-tensorrt-dev
#           - mod their dockerfile to install runtime version of all those packages
#   - copying ROS ressources is relatively easy, however copying ressources installed
#       via pip vs apt-get or via source installed or pytorch related is a nightmare.
#       Work around for minimizing maintenance: copy everything
# Ref:
#   - https://gitlab.com/nvidia/container-images/l4t-base
#   - https://gitlab.com/nvidia/container-images/l4t-jetpack
#   - https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-base
#   - https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-jetpack

ARG IS_TEAMCITY_RUN
ENV IS_TEAMCITY_RUN=${IS_TEAMCITY_RUN:-false}

SHELL ["/bin/bash", "-c"]
ARG DEBIAN_FRONTEND=noninteractive

ENV TZ=Etc/UTC
ENV TERM=${TERM:-"xterm-256color"}

# ....Transfer environment variable from base-images...............................................
# Env var specific to 'nvcr.io/nvidia/l4t-jetpack' base images
ARG CUDA_HOME
ARG NVIDIA_VISIBLE_DEVICES
ARG NVIDIA_DRIVER_CAPABILITIES
ARG PATH
ARG LD_LIBRARY_PATH

ENV CUDA_HOME=${CUDA_HOME}
ENV NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:?'Environment variable was not passed from base-image build stage'}
ENV NVIDIA_DRIVER_CAPABILITIES=${NVIDIA_DRIVER_CAPABILITIES:?'Environment variable was not passed from base-image build stage'}

# Note: Those are mandatory for CUDA to work
#   See https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions
ENV PATH=${PATH:?'Environment variable was not passed from base-image build stage'}
ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH:?'Environment variable was not passed from base-image build stage'}

# ....The following env var does not appear in every jetson-container ros base images..............
# En var added by jetson-container pytorch related base images
ARG OPENBLAS_CORETYPE
ENV OPENBLAS_CORETYPE=${OPENBLAS_CORETYPE}
ARG TORCH_HOME
ENV TORCH_HOME=${TORCH_HOME}

# En var added by jetson-container tensorflow related base images
ARG PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
ENV PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=${PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION}

# En var added by jetson-container 'dustynv/ros' base images
ARG LD_PRELOAD
ENV LD_PRELOAD=${LD_PRELOAD}

# En var added by 'nvcr.io/nvidia/pytorch' base images
ARG TENSORBOARD_PORT
ENV TENSORBOARD_PORT=${TENSORBOARD_PORT}
ARG JUPYTER_PORT
ENV JUPYTER_PORT=${JUPYTER_PORT}


## ....copy artifact from base-image...............................................................
## Note: copying ROS ressources is relatively easy, however copying ressources installed
##       via pip vs apt-get or via source installed or pytorch related is a nightmare.
##       Work around for minimizing maintenance: copy everything
#COPY --from=base-image /lib /lib
#COPY --from=base-image /etc /etc
#COPY --from=base-image /usr /usr
#COPY --from=base-image /bin /bin
#COPY --from=base-image /var /var
#COPY --from=base-image /opt /opt
#COPY --from=base-image ${ROS_ROOT} ${ROS_ROOT}

# ....Make python 3 default........................................................................
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3 1 \
    || update-alternatives --install /opt/conda/bin/python python /opt/conda/bin/python3 1

FROM squash-base-image AS squashed-base-image-tester

RUN echo "Check CUDA installed version"  \
    && nvcc --version | grep "release" | awk '{print $6}' | cut -c2-

RUN python -c "import numpy"

FROM squash-base-image AS final

ARG DN_TARGET_DEVICE
ENV DN_TARGET_DEVICE=${DN_TARGET_DEVICE:?err}
RUN echo "Dockerized-NorLab build system â€º image for target device: ${DN_TARGET_DEVICE:?err}"

CMD [ "bash" ]
