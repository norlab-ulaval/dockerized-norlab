
ARG BASE_IMAGE
ARG BASE_IMAGE_TAG
ARG MIMIC_DEPENDENCIES_BASE_IMAGE
ARG MIMIC_DEPENDENCIES_BASE_IMAGE_TAG
FROM --platform=linux/arm64 ${BASE_IMAGE:?err}:${BASE_IMAGE_TAG:?err} AS base-image
ARG TARGETPLATFORM
ARG BUILDPLATFORM
SHELL ["/bin/bash", "-c"]

# ★ Note: is reset on the project-develop, project-deploy last stage
ENV DEBIAN_FRONTEND=noninteractive
ENV PIP_ROOT_USER_ACTION=ignore

RUN <<EOF

    # ....Check pre-conditions.......................................................................
    {
        test -n "${TARGETPLATFORM:?'Env variable need to be set and non-empty.'}" && \
        test -n "${BUILDPLATFORM:?'Env variable need to be set and non-empty.'}" && \
        test -n "${DEBIAN_FRONTEND:?'Env variable need to be set and non-empty.'}" && \
        [[ "${DEBIAN_FRONTEND}" == "noninteractive" ]];
    } || { echo -e "\033[1;31m[DN error]\033[0m Failed pre-condition check" 1>&2 ; exit 1 ; }

    # ....Fetch pip installed packages list........................................................
    touch /requirements.l4t-base-image.txt
    (
      pip3 list --format freeze \
          --exclude onnx  \
          --exclude torchaudio  \
          --exclude tensorrt \
          --exclude torch2trt  \
          --exclude pycuda
    ) > /requirements.l4t-base-image.txt

    # ....Builder sanity check.....................................................................
    #echo "Show requirements.l4t-base-image.txt..."
    #more /requirements.l4t-base-image.txt
    #echo
    #echo -e "DEV introspection\n
    #Buildx env
    #  BUILDPLATFORM: ${BUILDPLATFORM}
    #  TARGETPLATFORM: ${TARGETPLATFORM}
    #Real build target architecture: $(uname -m)\n"

    if [[ "$(uname -m)" != "aarch64" ]]; then
        echo "[DN-build-system ERROR] L4T base images should be pulled as aarch64 platform. Something is wrong!" 1>&2
        exit 1
    fi

    # ....Remove Jetson-container unused component to save time and space during squashing.........
    rm --recursive --force /ros_deep_learning
    rm --recursive --force /jetson-inference
EOF

FROM --platform=linux/arm64 scratch AS base-image-arm64
# .................................................................................................
# Note:
#   - This stage is a workaround to prevent the "max depth exceeded" error
#        occuring when the maximum number of docker layer as been reached.
#   - We use 'scratch' as base image since for simplicity we are copying everything from l4t base image anyway.
#     We could use 'arm64v8/ubuntu:20.04' but it would require extra work yo discriminate
#   - About nvidia l4t base images:
#       - nvcr.io/nvidia/l4t-base install the core CUDA ressources
#       - nvcr.io/nvidia/l4t-jetpack
#           - install several dev package such as nvidia-cuda-dev, nvidia-cudnn-dev and nvidia-tensorrt-dev
#           - mod their dockerfile to install runtime version of all those packages
#   - copying ROS ressources is relatively easy, however copying ressources installed
#       via pip vs apt-get or via source installed or pytorch related is a nightmare.
#       Work around for minimizing maintenance: copy everything
# Ref:
#   - https://gitlab.com/nvidia/container-images/l4t-base
#   - https://gitlab.com/nvidia/container-images/l4t-jetpack
#   - https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-base
#   - https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-jetpack
# .................................................................................................
ARG TARGETPLATFORM
ARG TARGETARCH

# ★ Note: is reset on the project-develop, project-deploy last stage
ENV DEBIAN_FRONTEND=noninteractive

ARG IS_TEAMCITY_RUN
ENV IS_TEAMCITY_RUN=${IS_TEAMCITY_RUN:-false}

SHELL ["/bin/bash", "-c"]

ENV TZ=Etc/UTC
ENV TERM=${TERM:-"xterm-256color"}

# ....copy ALL artifact from base-image............................................................
COPY --from=base-image / /

## ....copy artifact from base-image...............................................................
## Note: copying ROS ressources is relatively easy, however copying ressources installed
##       via pip vs apt-get or via source installed or pytorch related is a nightmare.
##       Work around for minimizing maintenance: copy everything
#COPY --from=base-image /lib /lib
#COPY --from=base-image /etc /etc
#COPY --from=base-image /usr /usr
#COPY --from=base-image /bin /bin
#COPY --from=base-image /var /var
#COPY --from=base-image /opt /opt
#COPY --from=base-image ${ROS_ROOT} ${ROS_ROOT}

RUN <<EOF
    echo "(deb) Install basic utilities..."

    # ....Setup Sources............................................................................
    {
      apt-get update \
      && apt-get install --assume-yes --no-install-recommends \
            software-properties-common \
      && add-apt-repository --yes universe \
      && apt-get update;
    } || exit 1

    apt-get install --assume-yes --no-install-recommends \
            curl \
            pkg-config \
            lsb-release \
      || exit 1

    echo "Log build time environment variable..."
    printenv

    # Update symlink to point to system python3 instead of system python2
    update-alternatives --install /usr/bin/python python /usr/bin/python3 1 || exit 1
    update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1 || exit 1

    # ....Teardown.................................................................................
    apt-get autoremove --assume-yes
    apt-get clean
    rm -rf /var/lib/apt/lists/*
EOF

# ....Transfer environment variable from base-images...............................................
# Env var specific to 'nvcr.io/nvidia/l4t-jetpack' base images
ARG CUDA_HOME
ARG NVIDIA_VISIBLE_DEVICES
ARG NVIDIA_DRIVER_CAPABILITIES
ARG PATH
ARG LD_LIBRARY_PATH

ENV CUDA_HOME=${CUDA_HOME:?'Environment variable was not passed from base-image build stage'}
ENV NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:?'Environment variable was not passed from base-image build stage'}
ENV NVIDIA_DRIVER_CAPABILITIES=${NVIDIA_DRIVER_CAPABILITIES:?'Environment variable was not passed from base-image build stage'}

# Note: Those are mandatory for CUDA to work
#   See https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions
ENV PATH=${PATH:?'Environment variable was not passed from base-image build stage'}
ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH:?'Environment variable was not passed from base-image build stage'}

# ....The following env var does not appear in every jetson-container ros base images..............
# Env var added by jetson-container pytorch related base images
ARG OPENBLAS_CORETYPE
ENV OPENBLAS_CORETYPE=${OPENBLAS_CORETYPE}
ARG TORCH_HOME
ENV TORCH_HOME=${TORCH_HOME}

# The following pytorch related appeared in dustynv/cuda:12.2-r36.*
# Ref https://github.com/dusty-nv/jetson-containers/blob/master/packages/cuda/cuda/Dockerfile
ARG TORCH_NVCC_FLAGS
ARG TORCH_CUDA_ARCH_LIST
ENV TORCH_NVCC_FLAGS=${TORCH_NVCC_FLAGS}
ENV TORCH_CUDA_ARCH_LIST=${TORCH_CUDA_ARCH_LIST}

## Env var added by jetson-container tensorflow related base images
#ARG PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
#ENV PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=${PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION}

# Env var added by jetson-container 'dustynv/ros' base images
ARG LD_PRELOAD
ENV LD_PRELOAD=${LD_PRELOAD}

# The following cuda related appeared in dustynv/cuda:12.2-r36.*
# Ref https://github.com/dusty-nv/jetson-containers/blob/master/packages/cuda/cuda/Dockerfile
ARG CMAKE_CUDA_COMPILER
ARG CUDA_BIN_PATH
ARG CUDAARCHS
ARG CUDACXX
ARG CUDA_TOOLKIT_ROOT_DIR
ARG NVCC_PATH
ARG CUDA_NVCC_EXECUTABLE
ARG CUDA_ARCHITECTURES
ENV CMAKE_CUDA_COMPILER=${CMAKE_CUDA_COMPILER}
ENV CUDA_BIN_PATH=${CUDA_BIN_PATH}
ENV CUDAARCHS=${CUDAARCHS}
ENV CUDACXX=${CUDACXX}
ENV CUDA_TOOLKIT_ROOT_DIR=${CUDA_TOOLKIT_ROOT_DIR}
ENV NVCC_PATH=${NVCC_PATH}
ENV CUDA_NVCC_EXECUTABLE=${CUDA_NVCC_EXECUTABLE}
ENV CUDA_ARCHITECTURES=${CUDA_ARCHITECTURES}


FROM --platform=linux/amd64 ${MIMIC_DEPENDENCIES_BASE_IMAGE:?err}:${MIMIC_DEPENDENCIES_BASE_IMAGE_TAG:?err} AS base-image-amd64
ARG TARGETPLATFORM
ARG TARGETARCH

# ★ Note: is reset on the project-develop, project-deploy last stage
ENV DEBIAN_FRONTEND=noninteractive

ARG IS_TEAMCITY_RUN
ENV IS_TEAMCITY_RUN=${IS_TEAMCITY_RUN:-false}
ENV TZ=Etc/UTC
ENV TERM=${TERM:-"xterm-256color"}
SHELL ["/bin/bash", "-c"]

ARG UBUNTU_VERSION_MAJOR

RUN <<EOF
    # ....Check pre-conditions.......................................................................
    {
        test -n "${UBUNTU_VERSION_MAJOR:?'Env variable need to be set and non-empty.'}" && \
        test -n "${TARGETPLATFORM:?'Env variable need to be set and non-empty.'}" && \
        test -n "${DEBIAN_FRONTEND:?'Env variable need to be set and non-empty.'}" && \
        [[ "${DEBIAN_FRONTEND}" == "noninteractive" ]];
    } || { echo -e "\033[1;31m[DN error]\033[0m Failed pre-condition check" 1>&2 ; exit 1 ; }

    echo "(deb) Install basic utilities..."

    # ....Setup Sources............................................................................
    apt-get update
    apt-get install --assume-yes --no-install-recommends software-properties-common
    add-apt-repository --yes universe
    # Update again since we added a new key
    apt-get update

    apt-get install --assume-yes --no-install-recommends \
        curl \
        pkg-config \
        lsb-release \
        gcc \
        python3-dev \
        python3-pip

    echo "Log build time environment variable..."
    printenv

    IMG_RELEASE="$( source /etc/lsb-release && echo ${DISTRIB_RELEASE})"
    if [[ "${UBUNTU_VERSION_MAJOR:?err}.04" != "${IMG_RELEASE}" ]]; then
      echo -e "Expected Ubuntu distro release ${UBUNTU_VERSION_MAJOR}.04 but image distro is ${IMG_RELEASE}!" 1>&2
      exit 1
    fi

    # ....Make python 3 default........................................................................
    # Update symlink to point to system python3 instead of system python2
    update-alternatives --install /usr/bin/python python /usr/bin/python3 1
    update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1

    # ....Install python utilities..................................................................
    python3 -m pip install --upgrade pip

    pip3 install --no-cache-dir \
        wheel \
        setuptools \
        packaging \
        Cython

        # 'Cython<3' # Why was it set to lower than 3 !?!

    pip3 install --no-cache-dir  \
          wget \
          psutil

    # ....Teardown.................................................................................
    apt-get autoremove --assume-yes
    apt-get clean
    rm -rf /var/lib/apt/lists/*
EOF


FROM --platform=linux/amd64 base-image-amd64 AS mimic-l4t-image
ARG TARGETPLATFORM
ARG TARGETARCH

ARG IS_TEAMCITY_RUN
ENV IS_TEAMCITY_RUN=${IS_TEAMCITY_RUN:-false}

COPY --from=base-image /requirements.l4t-base-image.txt /requirements.l4t-base-image.txt

RUN <<EOF
    # ....Check pre-conditions.....................................................................
    {
        test -n "${UBUNTU_VERSION_MAJOR:?'Env variable need to be set and non-empty.'}" && \
        test -n "${TARGETPLATFORM:?'Env variable need to be set and non-empty.'}" && \
        test -n "${TARGETARCH:?'Env variable need to be set and non-empty.'}" && \
        test -n "${DEBIAN_FRONTEND:?'Env variable need to be set and non-empty.'}" && \
        [[ "${DEBIAN_FRONTEND}" == "noninteractive" ]];
    } || { echo -e "\033[1;31m[DN error]\033[0m Failed pre-condition check" 1>&2 ; exit 1 ; }

    # ....Reinstall l4t image package in amd64 image...............................................
    apt-get update

    if [[ ${TARGETPLATFORM} =~ "linux/amd64".* ]]; then

        echo "Install general utilities..."
        apt-get install --assume-yes --no-install-recommends \
            software-properties-common \
            apt-transport-https \
            apt-utils \
            ca-certificates \
            lsb-release \
            build-essential \
            pkg-config \
            gnupg \
            git \
            wget \
            curl \
            nano \
            zip \
            unzip

        echo "Install pytorch utilities..."
        apt-get install --assume-yes --no-install-recommends \
            libopenblas-dev \
            libopenmpi-dev \
            openmpi-bin \
            openmpi-common \
            gfortran \
            libomp-dev

        pip3 install --no-cache-dir \
            scikit-build  \
            ninja

    fi

    # ....Install l4t image ubuntu apt requirement.................................................
    echo "Install l4t image ubuntu apt requirement..."
    # Install pycuda related
    #   Build instruction: https://github.com/berlinguyinca/pycuda/blob/master/doc/source/install.rst
    #
    # Requirement for 'pycairo' which is required by 'pycuda'
    apt-get install --assume-yes --no-install-recommends \
      libcairo2-dev

    # ....Install l4t image python requirement from file...........................................
    echo "Install l4t image python requirement from file..."
    # Requirement for 'graphsurgeon' and 'uff', it give access to nvidia pip index

    # (CRITICAL) ToDo: fix the build 210 nvidia-pyindex install problem
    # ref http://132.203.26.125:8111/buildConfiguration/DockerizedNorlab_BuildAndPushMultiArchDockerImages/13322
    #pip3 install --no-cache-dir nvidia-pyindex
    #python3 -m pip install --upgrade pip
    #python3 -m pip install wheel setuptools
    ## Install with --no-build-isolation to avoid the subprocess pip issue
    #python3 -m pip install --no-build-isolation nvidia-pyindex
    #pip3 install --no-cache-dir \
    #    --extra-index-url https://pypi.ngc.nvidia.com \
    #    nvidia-pyindex || echo "nvidia-pyindex installation optional, continuing..."
    python3 -m pip install onnx_graphsurgeon uff --extra-index-url https://pypi.ngc.nvidia.com

    if [[ ${TARGETPLATFORM} =~ "linux/amd64".* ]]; then
        echo "Strip versions from requirement"
        sed -i.bak 's/nvidia-pyindex.*//g' /requirements.l4t-base-image.txt
        sed -i.bak 's/==.*//g' /requirements.l4t-base-image.txt
        pip3 install -r /requirements.l4t-base-image.txt || exit 1

        # Clean up sed tmp file
        rm /requirements.l4t-base-image.txt.bak
    fi

    # Explicit install step for torch2trt and tensorrt (ref task TASK)
    # Note: python import of either torch2trt and tensorrt whithout host cuda support will return an error
    # Ref
    #   - https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing
    #   - https://github.com/NVIDIA-AI-IOT/torch2trt
    #   - https://github.com/dusty-nv/jetson-containers/blob/master/packages/pytorch/torch2trt/Dockerfile
    #

    # pip3 install git+https://github.com/NVIDIA-AI-IOT/torch2trt
    if [[ ${TARGETPLATFORM} =~ "linux/amd64".* ]]; then
        cd /opt
        git clone https://github.com/NVIDIA-AI-IOT/torch2trt
        cd torch2trt
        python3 setup.py install || exit 1
    fi

    # ....Teardown.................................................................................
    apt-get autoremove --assume-yes
    apt-get clean
    rm -rf /var/lib/apt/lists/*
EOF

FROM --platform=linux/arm64 base-image-arm64 AS final-arm64
ARG TARGETPLATFORM
ARG TARGETARCH
ARG BUILDPLATFORM

CMD [ "bash" ]

FROM --platform=linux/amd64 mimic-l4t-image AS final-amd64
ARG TARGETPLATFORM
ARG TARGETARCH
ARG BUILDPLATFORM

CMD [ "bash" ]


FROM --platform=${TARGETPLATFORM} final-${TARGETARCH} AS test
ARG TARGETPLATFORM
ARG TARGETARCH
ARG BUILDPLATFORM

RUN <<EOF
    # ....Check pre-conditions.......................................................................
    {
        test -n "${TARGETPLATFORM:?'Env variable need to be set and non-empty.'}" && \
        test -n "${BUILDPLATFORM:?'Env variable need to be set and non-empty.'}" && \
        test -n "${DEBIAN_FRONTEND:?'Env variable need to be set and non-empty.'}" && \
        [[ "${DEBIAN_FRONTEND}" == "noninteractive" ]];
    } || { echo -e "\033[1;31m[DN error]\033[0m Failed pre-condition check" 1>&2 ; exit 1 ; }


    echo -e "Current python version: $(python --version)
          which python: $(which python)
        whereis python: $(whereis python)
             which pip: $(which pip)
           whereis pip: $(whereis pip)"

    if [[ ! $(python --version) =~ "Python 3.".* ]]; then
        echo "Require python 3 but current verison is $(python --version)" 1>&2
        exit 1
    fi

    if [[ $(which python) != "/usr/bin/python" ]] || [[ $(which python) == "/opt/conda/bin/python" ]]; then
        echo -e "ROS2 does not behave well with conda python environment, make sure the default python is either the system python or a virtual environment"
        echo -e "Ref https://docs.ros.org/en/rolling/How-To-Guides/Installation-Troubleshooting.html#anaconda-python-conflict"
        exit 1
    fi

    printenv

    if [[ ${TARGETPLATFORM} =~ "linux/arm64".* ]]; then
      {
        test -n ${CUDA_HOME:?'Environment variable was not passed from base-image build stage to test stage'} && \
        test -n ${NVIDIA_VISIBLE_DEVICES:?'Environment variable was not passed from base-image build stage to test stage'} && \
        test -n ${NVIDIA_DRIVER_CAPABILITIES:?'Environment variable was not passed from base-image build stage to test stage'} && \
        test -n ${PATH:?'Environment variable was not passed from base-image build stage to test stage'} && \
        test -n ${LD_LIBRARY_PATH:?'Environment variable was not passed from base-image build stage to test stage'} ;
      } || { echo "Missing required environment variables!" 1>&2 ; exit 1 ; }
    fi

    echo "Check CUDA installed version"
    nvcc --version | grep "release" | awk '{print $6}' | cut -c2-

    echo -e "\n----------------------------------------------------------\n"
    echo -e "        TARGETPLATFORM: $(echo ${TARGETPLATFORM:?'Env var not set in container'})"
    echo -e "            TARGETARCH: $(echo ${TARGETARCH:?'Env var not set in container'})"
    echo -e "                  PATH: $(echo $PATH)"
    echo -e "\n----------------------------------------------------------\n"
    echo -e "           which pip's: $(which pip pip3)"
    echo -e "              pip list: $(pip list)"
    echo -e "\n----------------------------------------------------------\n"
    pip3 show pycuda
    python3 -c "import pycuda; print( pycuda.VERSION_TEXT )"
    echo -e "\n----------------------------------------------------------\n"
    pip3 show torch
    python3 -c "import torch; print( f'CUDA is available: {torch.cuda.is_available()}' )"
    echo -e "\n----------------------------------------------------------\n"

    # Note: see https://docs.docker.com/engine/reference/builder/#automatic-platform-args-in-the-global-scope
    #       for docker buildx environment variables available inside the container: i.e. [TARGET|BUILD]PLATFORM

    echo -e "Ubuntu version is $( source /etc/lsb-release && echo ${DISTRIB_CODENAME})"

    echo "Dockerized-NorLab build system › image for target device: ${TARGETPLATFORM:?'Buildx environment variables not available in container'}"
    echo -e "DEV introspection\n
    Buildx env
      BUILDPLATFORM: ${BUILDPLATFORM:?err}
      TARGETPLATFORM: ${TARGETPLATFORM}
    Real build target architecture: $(uname -m)\n"

    if [[ "${TARGETPLATFORM}" =~ "linux/arm64".* ]] && [[ "$(uname --machine)" == "x86_64" ]]; then
        echo "[DN-build-system ERROR] Test stage architecture missmatch!" 1>&2
        exit 1
    fi
EOF
